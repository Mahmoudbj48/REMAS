{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a6233dc",
   "metadata": {},
   "source": [
    "## User Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cba8fde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running REMAS: run_user_parser_agent\n",
      "✅ Upserted 1 points into 'user_agent_listings' without resetting the collection.\n",
      "✅ Uploaded user query with ID: 6e9fd5b8e158c408a80980e25e049dac to 'user_agent_listings'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'6e9fd5b8e158c408a80980e25e049dac'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agents.user_parser_agent import invoke_user_parser_agent\n",
    "\n",
    "print(\"Running REMAS: user_parser_agent\")\n",
    "user_input = input(\"Type your message: \")\n",
    "\n",
    "invoke_user_parser_agent(user_input=user_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e64c3db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user Qdrant count: 1001\n"
     ]
    }
   ],
   "source": [
    "from utils.qdrant_connection import count_qdrant\n",
    "print(\"user Qdrant count:\", count_qdrant(\"user_agent_listings\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61745f9d",
   "metadata": {},
   "source": [
    "## Owner Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa570ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running REMAS: owner_parser_agent\n",
      "✅ Upserted 1 points into 'owner_agent_listings' without resetting the collection.\n",
      "✅ Uploaded owner listing with ID: 140d392e74131263a9ca770865306117 to 'owner_agent_listings'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'140d392e74131263a9ca770865306117'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from agents.owner_parser_agent import invoke_owner_parser_agent\n",
    "\n",
    "print(\"Running REMAS: owner_parser_agent\")\n",
    "owner_input = input(\"Type your message: \")\n",
    "\n",
    "invoke_owner_parser_agent(owner_input=owner_input)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee4f5715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "owner Qdrant count: 1008\n"
     ]
    }
   ],
   "source": [
    "from utils.qdrant_connection import count_qdrant\n",
    "print(\"owner Qdrant count:\", count_qdrant(\"owner_agent_listings\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0769399",
   "metadata": {},
   "source": [
    "## SYNTHIETIC DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f07cf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# -------- prompts --------\n",
    "OWNER_NORMALIZE_PROMPT = \"\"\"You will receive a short listing description pulled from Airbnb data (may be informal).\n",
    "Rewrite it as a concise, normal real-estate OWNER listing (2–4 sentences).\n",
    "Include: location, bedrooms, notable perks/constraints, monthly price (if present), and availability timing (if present).\n",
    "Output plain text only.\"\"\"\n",
    "\n",
    "CUSTOMER_SYNTH_PROMPT = \"\"\"You will receive a normal real-estate OWNER listing.\n",
    "Rewrite it as a RENTER request that naturally matches it (1–3 sentences).\n",
    "Mention location, min bedrooms, lifestyle hints, max monthly budget (same number), and move-in time if present.\n",
    "Output plain text only.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56157c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------- helpers --------\n",
    "def _chat(messages: List[dict]) -> str:\n",
    "    r = client.chat.completions.create(\n",
    "        model=MODEL_ID,\n",
    "        messages=messages,\n",
    "        temperature=TEMP\n",
    "    )\n",
    "    return r.choices[0].message.content.strip()\n",
    "\n",
    "def select_seed_listings(csv_path: str, n: int) -> pd.DataFrame:\n",
    "    df = pd.read_csv(csv_path)\n",
    "    df[\"state\"] = df[\"state\"].astype(str).str.upper().str.strip()\n",
    "    df = df[df[\"state\"].isin(CITY_FILTER)]\n",
    "    if len(df) > n:\n",
    "        df = df.sample(n=n, random_state=42)\n",
    "    return df.reset_index(drop=True)\n",
    "\n",
    "def build_airbnb_source_text(row: pd.Series) -> str:\n",
    "    \"\"\"Compose a compact source text from structured fields (since Airbnb text may be odd).\"\"\"\n",
    "    parts = []\n",
    "    b = row.get(\"bedrooms\")\n",
    "    if pd.notna(b):\n",
    "        parts.append(f\"{int(b)}-bedroom\")\n",
    "    city = str(row.get(\"state\") or \"\").title()\n",
    "    if city:\n",
    "        parts.append(f\"in {city}\")\n",
    "    soft = (row.get(\"soft_attributes\") or \"\").strip()\n",
    "    price = row.get(\"price\")\n",
    "    avail = (row.get(\"available_from\") or \"\")\n",
    "    s = f\"{' '.join(parts)}. {soft}\".strip()\n",
    "    if pd.notna(price):\n",
    "        s += f\" Price: ${int(float(price))}/month.\"\n",
    "    if isinstance(avail, str) and avail:\n",
    "        s += f\" Available from {avail.title()}.\"\n",
    "    return s[:800]\n",
    "\n",
    "def owner_normalize(text: str) -> str:\n",
    "    return _chat([\n",
    "        {\"role\": \"system\", \"content\": OWNER_NORMALIZE_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": text}\n",
    "    ])\n",
    "\n",
    "def customer_from_owner(owner_text: str) -> str:\n",
    "    return _chat([\n",
    "        {\"role\": \"system\", \"content\": CUSTOMER_SYNTH_PROMPT},\n",
    "        {\"role\": \"user\", \"content\": owner_text}\n",
    "    ])\n",
    "\n",
    "def save_jsonl(path: str, rows: List[dict]):\n",
    "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        for r in rows:\n",
    "            json.dump(r, f, ensure_ascii=False)\n",
    "            f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef59328d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 1000 rows from ['NEW YORK', 'NEW YORK CITY', 'NYC', 'SAN FRANCISCO']\n"
     ]
    }
   ],
   "source": [
    "df = select_seed_listings(CSV_PATH, N_SAMPLES)\n",
    "if df.empty:\n",
    "    print(\"No rows after filtering.\")\n",
    "print(f\"Selected {len(df)} rows from {sorted(CITY_FILTER)}\")\n",
    "df.to_csv(SELCTED_PATH, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "363d07c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: build source (Airbnb-ish) text → normalize to owner style\n",
    "owner_inputs: List[str] = []\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"Normalize owner texts\"):\n",
    "    src = build_airbnb_source_text(row)\n",
    "    owner_inputs.append(owner_normalize(src))\n",
    "    time.sleep(0.02)  # gentle pacing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9493583e",
   "metadata": {},
   "source": [
    "# OLD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47cc2e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from config.llm_config import llm\n",
    "# from agents.leave_me_agent import run_leave_me_agent\n",
    "\n",
    "# def main():\n",
    "#     print(\"Running REMAS: Leave Me Agent Example\")\n",
    "#     user_input = input(\"Type your message: \")\n",
    "\n",
    "#     response = run_leave_me_agent(user_input=user_input, llm=llm)\n",
    "#     print(\"Agent Response:\", response)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d795777",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from remas_llm import run_llm_agent\n",
    "\n",
    "# response = run_llm_agent(\n",
    "#     user_input=\"Hello there!\",\n",
    "#     system_prompt=\"You must always respond with: Leave me alone!\"\n",
    "# )\n",
    "# print(\"Agent:\", response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546ee27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load environment variables\n",
    "# load_dotenv()\n",
    "# AZURE_OPENAI_API_KEY = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "# DEPLOYMENT_NAME = \"team8-gpt4o\"  \n",
    "# AZURE_OPENAI_ENDPOINT = \"https://096290-oai.openai.azure.com\"\n",
    "# API_VERSION = \"2023-05-15\"\n",
    "\n",
    "# # Initialize model\n",
    "# llm = AzureChatOpenAI(\n",
    "#     api_key=AZURE_OPENAI_API_KEY,\n",
    "#     api_version=API_VERSION,\n",
    "#     azure_endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "#     deployment_name=DEPLOYMENT_NAME,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e45dde39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Token usage log file\n",
    "# LOG_FILE = \"token_usage.csv\"\n",
    "\n",
    "# # Ensure CSV file has headers\n",
    "# if not os.path.exists(LOG_FILE):\n",
    "#     with open(LOG_FILE, mode='w', newline='') as f:\n",
    "#         writer = csv.writer(f)\n",
    "#         writer.writerow([\"timestamp\", \"input_tokens\", \"output_tokens\", \"total_tokens\", \"user_input\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718e14d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def run_llm_agent(user_input):\n",
    "#     messages = [\n",
    "#         SystemMessage(content=\"You must always respond with: Leave me alone!\"),\n",
    "#         HumanMessage(content=user_input)\n",
    "#     ]\n",
    "\n",
    "#     # Token usage tracking\n",
    "#     with get_openai_callback() as cb:\n",
    "#         response = llm.invoke(messages)\n",
    "\n",
    "#         # Log to CSV\n",
    "#         with open(LOG_FILE, mode='a', newline='') as f:\n",
    "#             writer = csv.writer(f)\n",
    "#             writer.writerow([\n",
    "#                 datetime.now().isoformat(),\n",
    "#                 cb.prompt_tokens,\n",
    "#                 cb.completion_tokens,\n",
    "#                 cb.total_tokens,\n",
    "#                 user_input\n",
    "#             ])\n",
    "\n",
    "#     return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f732ad0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Agent: Leave me alone!\n",
      "Agent: Leave me alone!\n"
     ]
    }
   ],
   "source": [
    "# while True:\n",
    "#     user_input = input(\"User: \")\n",
    "#     if user_input.lower() in {\"exit\", \"quit\"}:\n",
    "#         break\n",
    "#     response = run_llm_agent(user_input)\n",
    "#     print(\"Agent:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a933903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import re\n",
    "\n",
    "# def extract_outputs(results):\n",
    "#     outputs = []\n",
    "#     for r in results:\n",
    "#         match = re.search(r\"<output>\\s*(\\d)\\s*</output>\", r)\n",
    "#         if match and match.group(1) in [\"0\", \"1\"]:\n",
    "#             outputs.append(int(match.group(1)))\n",
    "#         else:\n",
    "#             outputs.append(-1)\n",
    "#     return outputs\n",
    "\n",
    "# def extract_explanations(results):\n",
    "#     explanations = []\n",
    "#     for r in results:\n",
    "#         match = re.search(r\"<explanation>\\s*(.*?)\\s*</explanation>\", r, re.DOTALL)\n",
    "#         if match:\n",
    "#             explanations.append(match.group(1).strip())\n",
    "#         else:\n",
    "#             explanations.append(\"\")\n",
    "#     return explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e946edbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -------------------- \n",
    "# # a function for inserting a system and user messages into a conversation\n",
    "# # -------------------- \n",
    "# def format_prompt(system_msg: str, user_msg: str):\n",
    "#     return [\n",
    "#         SystemMessage(content=system_msg), \n",
    "#         HumanMessage(content=user_msg)\n",
    "#     ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b526f11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -------------------- \n",
    "# # invoking a single call\n",
    "# # -------------------- \n",
    "\n",
    "# system_msg = \"Answer 'Leave me alone' no matter what you're asked.\"\n",
    "# user_msg = \"What is the capital of France?\"\n",
    "# prompt = format_prompt(system_msg, user_msg)\n",
    "# result = gpt_4o.invoke(prompt).content   # output: \"Leave me alone.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6822c215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # -------------------- \n",
    "# # a function for running multiple calls in parallel\n",
    "# # -------------------- \n",
    "# def invoke_llm(model: AzureChatOpenAI, prompts: list[str] | list[list[SystemMessage | HumanMessage]], with_tqdm=True) -> \\\n",
    "#         list[str]:\n",
    "#     def single_invoke(prompt: str) -> str:\n",
    "#         try:\n",
    "#             result = model.invoke(prompt)\n",
    "#             return result.content\n",
    "#         except Exception as e:\n",
    "#             print(f\"LLM error: {e}\")\n",
    "#             return \"N/A\"\n",
    "\n",
    "#     with ThreadPoolExecutor() as executor:\n",
    "#         if with_tqdm:\n",
    "#             results = list(tqdm(\n",
    "#                 executor.map(single_invoke, prompts),\n",
    "#                 total=len(prompts),\n",
    "#                 desc=\"Processing prompts\"\n",
    "#             ))\n",
    "#         else:\n",
    "#             results = list(executor.map(single_invoke, prompts))\n",
    "\n",
    "#     return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4552caa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
